############################
# rag-service (.env) - Nivel Máster
############################

APP_ENV=local
APP_DEBUG=0

# Cliente LLM (microservicio OpenAI)
OPENAI_SERVICE_URL=http://localhost:8081/v1/chat

# Firma interna HMAC
INTERNAL_API_KEY=change-me-strong-random

# RAG embeddings (opcional)
RAG_USE_EMBEDDINGS=0
RAG_EMBEDDINGS_AUTOREFRESH=0
RAG_LOG_FILE=storage/logs/rag.log

# Circuit Breaker (OpenAI Service)
CB_FAILURE_THRESHOLD=3
CB_OPEN_TTL_SECONDS=30
CB_HALF_OPEN_MAX_CALLS=1
CB_STATE_FILE=storage/ai/circuit_breaker.json

# Solo si generas embeddings con OpenAI directamente desde este servicio
OPENAI_API_KEY=

# Logs de tokens
# Ruta absoluta donde se escriben los logs de tokens en hosting
# En local dejar vacío para usar la ruta relativa por defecto (storage/ai/tokens.log)
TOKENS_LOG_PATH=
# Log unificado (app principal + RAG). En hosting apuntar al storage central.
# AI_TOKENS_LOG_PATH=/home/u968396048/domains/contenido.creawebes.com/public_html/iamasterbigschool/storage/ai/tokens.log
