# rag-service

Microservicio PHP encargado de la comparaci√≥n RAG de h√©roes para **Clean Marvel Album**.

## Arranque r√°pido

```bash
composer install
php -S localhost:8082 -t public
```

- Expone `POST /rag/heroes`.
- Depende del microservicio OpenAI (`http://localhost:8081/v1/chat`) para generar la respuesta final.
- El frontend (8080) solo consume el resultado y muestra la tabla + conclusi√≥n.

## Configuraci√≥n

- Con la variable de entorno `OPENAI_SERVICE_URL` puedes cambiar el endpoint del microservicio de OpenAI. Por defecto usa `http://localhost:8081/v1/chat`.
- La base de conocimiento vive en `storage/knowledge/heroes.json`. Actual√≠zala cuando agregues h√©roes nuevos relevantes para las comparaciones.

## Modos de retrieval (l√©xico vs vectorial)

- **L√©xico (default):** usa bolsa de palabras y similitud coseno en memoria. Es el modo activo por defecto y no necesita embeddings ni claves adicionales.
- **Vectorial (embeddings, opcional):** calcula similitud usando embeddings de los h√©roes y la pregunta. Se activa con `RAG_USE_EMBEDDINGS=1`. Si faltan vectores o algo falla, el servicio hace fallback autom√°tico al retriever l√©xico para no interrumpir el flujo.
- **Autorefresco opcional:** `RAG_EMBEDDINGS_AUTOREFRESH=1` permite generar y guardar embeddings faltantes en caliente; si no est√° activo, sigue usando el modo l√©xico cuando no haya vectores.
- **Generaci√≥n offline de embeddings:** ejecuta `php generate_embeddings.php` desde la ra√≠z de `rag-service/` (requiere `OPENAI_API_KEY`) para poblar `storage/embeddings/heroes.json` sin gastar tokens en producci√≥n.
- **Compatibilidad:** el endpoint `POST /rag/heroes` y el caso de uso `compare()` permanecen id√©nticos; solo cambia la estrategia de ranking interna seg√∫n la configuraci√≥n.

## Tests del microservicio

- Este microservicio tiene su propia bater√≠a de tests en `rag-service/tests/` con configuraci√≥n dedicada `rag-service/phpunit.xml`.
- Ejecuta los tests desde la carpeta ra√≠z del repo con: `cd rag-service && ../vendor/bin/phpunit`.

## Trabajo futuro / mejoras posibles

- Vector store s√≥lido (SQLite/FAISS/Qdrant/Chroma) con adaptador `RetrieverInterface`, manteniendo fallback l√©xico.
- Observabilidad: logs estructurados, m√©tricas de latencia y trazas (p.ej., OpenTelemetry) para seguir el flujo.
- Resiliencia LLM: circuit breakers, rate limiting y reintentos con backoff hacia el servicio OpenAI.
- Cache de respuestas por combinaci√≥n de `heroIds` + pregunta normalizada para ahorrar tokens en consultas repetidas.
- Pipeline de embeddings programado que regenere vectores cuando cambie `storage/knowledge/heroes.json`.
- Validaciones extra: limpieza/normalizaci√≥n de inputs, l√≠mites de longitud y cantidad de `heroIds`.
- QA continua: CI con PHPUnit + PHPStan, tests contractuales del endpoint `/rag/heroes` y smoke tests del modo vectorial activado.

## Request / Response

**Request**

```json
{
  "question": "Compara sus atributos y resume el resultado",
  "heroIds": ["id-1", "id-2"]
}
```

**Response**

```json
{
  "answer": "Atributo | Valoraci√≥n\nAtaque | ...\n\nüß© ...",
  "contexts": [
    { "heroId": "id-1", "nombre": "Iron Man", "contenido": "...", "score": 0.91 }
  ],
  "heroIds": ["id-1", "id-2"]
}
```

Si ocurre un error, devuelve `{ "error": "mensaje" }` con el c√≥digo HTTP correspondiente.
